#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
êµë³´ ê³„ì—´ì‚¬ 13ê°œ ì‚¬ì´íŠ¸ ì „ì²´ ìŠ¤í¬ë˜í•‘
"""

import os
import requests
from datetime import datetime

# 13ê°œ ì‚¬ì´íŠ¸ URL ë¦¬ìŠ¤íŠ¸
KYOBO_URLS = [
    ("êµë³´ë¬¸ê³ ", "í†µí•©PC", "https://mmbr.kyobobook.co.kr/login"),
    ("êµë³´ë¬¸ê³ ", "eBook", "https://mmbr.kyobobook.co.kr/login?continue=https://ebook.kyobobook.co.kr/"),
    ("êµë³´ë¬¸ê³ ", "samì •ì•¡êµ¬ë…", "https://mmbr.kyobobook.co.kr/login?continue=https://sam.kyobobook.co.kr/"),
    ("êµë³´ë¬¸ê³ ", "í•«íŠ¸ë™ìŠ¤ëª°", "https://mmbr.kyobobook.co.kr/login?continue=https://hottracks.kyobobook.co.kr/"),
    ("êµë³´ë¬¸ê³ ", "ìŠ¤í† ë¦¬í”Œë«í¼", "https://mmbr.kyobobook.co.kr/login?continue=https://storynew.kyobobook.co.kr/"),
    ("êµë³´ë¬¸ê³ ", "í•«íŠ¸ë™ìŠ¤ê´€ë¦¬ì", "https://admin.hottracks.co.kr/admin/login/form"),
    ("êµë³´ìƒëª…", "í†µí•©ë¡œê·¸ì¸", "https://www.kyobo.com/dgt/web/dtm/lc/tu/login"),
    ("êµë³´ìƒëª…", "ê¸ˆìœµì¸ì¦ì„œ", "https://www.kyobo.com/dgt/web/dtm/lc/tu/kftcLogin"),
    ("êµë³´ìƒëª…", "ì¹´ì¹´ì˜¤ì¸ì¦ì„œ", "https://www.kyobo.com/dgt/web/dtm/lc/tu/kakaoLogin"),
    ("êµë³´ìƒëª…", "í† ìŠ¤ì¸ì¦ì„œ", "https://www.kyobo.com/dgt/web/dtm/lc/tu/tossLogin"),
    ("êµë³´ìƒëª…", "ì‚¬ë‚´SmartON", "https://sso.kyobo.com:5443/3rdParty/certLoginFormPage.jsp"),
    ("êµë³´ë¼ì´í”„í”Œë˜ë‹›", "í†µí•©PC", "https://www.lifeplanet.co.kr/lpds2/common/ua/UA01001S.dev"),
    ("êµë³´ì¦ê¶Œ", "ê³ ê°í¬í„¸PC", "https://www.iprovest.com/weblogic/LOginServlet")
]

def create_folders():
    """ë‚ ì§œë³„ í´ë” êµ¬ì¡° ìƒì„±"""
    date_str = datetime.now().strftime("%Y-%m-%d")
    base_dir = f"kyobo_scraping_{date_str}"
    
    # ê¸°ë³¸ í´ë” ìƒì„±
    os.makedirs(base_dir, exist_ok=True)
    
    # ê´€ê³„ì‚¬ë³„ í´ë” ìƒì„±
    companies = ["êµë³´ë¬¸ê³ ", "êµë³´ìƒëª…", "êµë³´ë¼ì´í”„í”Œë˜ë‹›", "êµë³´ì¦ê¶Œ"]
    for company in companies:
        company_dir = os.path.join(base_dir, company)
        os.makedirs(company_dir, exist_ok=True)
    
    return base_dir

def fetch_html(url):
    """HTML ê°€ì ¸ì˜¤ê¸°"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        return response.text
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        return None

def scrape_all():
    """ì „ì²´ ìŠ¤í¬ë˜í•‘ ì‹¤í–‰"""
    print("ğŸš€ êµë³´ ê³„ì—´ì‚¬ 13ê°œ ì‚¬ì´íŠ¸ ìŠ¤í¬ë˜í•‘ ì‹œì‘")
    print("="*50)
    
    base_dir = create_folders()
    timestamp = datetime.now().strftime("%H%M%S")
    
    success = 0
    total = len(KYOBO_URLS)
    
    for i, (company, service, url) in enumerate(KYOBO_URLS, 1):
        print(f"[{i}/{total}] {company} - {service}")
        print(f"  URL: {url}")
        
        # HTML ê°€ì ¸ì˜¤ê¸°
        html = fetch_html(url)
        
        if html:
            # íŒŒì¼ ì €ì¥
            filename = f"{service}_{timestamp}.html"
            filepath = os.path.join(base_dir, company, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(html)
            
            print(f"  âœ… ì €ì¥: {filepath} ({len(html):,} ë¬¸ì)")
            success += 1
        else:
            print(f"  âŒ ì‹¤íŒ¨")
        
        print()
    
    print("ğŸ“‹ ì™„ë£Œ ìš”ì•½")
    print("="*50)
    print(f"âœ… ì„±ê³µ: {success}/{total}")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {base_dir}")
    
    # í´ë”ë³„ íŒŒì¼ ê°œìˆ˜
    for company in ["êµë³´ë¬¸ê³ ", "êµë³´ìƒëª…", "êµë³´ë¼ì´í”„í”Œë˜ë‹›", "êµë³´ì¦ê¶Œ"]:
        company_dir = os.path.join(base_dir, company)
        if os.path.exists(company_dir):
            files = [f for f in os.listdir(company_dir) if f.endswith('.html')]
            print(f"  {company}: {len(files)}ê°œ íŒŒì¼")

if __name__ == "__main__":
    scrape_all()